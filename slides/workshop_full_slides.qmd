---
title: "DevOps for Data Scientists"
subtitle: | 
  |
  | Wifi: Posit Conf 2023
  | password: conf2023
title-slide-attributes: 
  data-background-color: white
  data-background-image: _extensions/positconfslides/assets/backgrounds/toc-light.svg
  data-background-size: contain
format:
  positconfslides-revealjs: 
    chalkboard: true
    slide-number: true
    footer: <https://github.com/posit-conf-2023/DevOps>
    incremental: false
    code-copy: true
    center-title-slide: false
    code-link: true
    code-overflow: wrap
    highlight-style: a11y
    width: "1600"
    height: "900"
    filters:
      - positconfslides
---

## Part 1: Introductions, setup, & workshop overview {.toc-people-dark}

## Meet your instructors

::: panel-tabset
## Rika

![](images/rika_bio-01.jpeg){width="25%"}

-   Solutions Engineer at Posit

-   Former Data Scientist and Data Engineer

## Andrie

![](images/Andrie%20square%20500px.jpg){width="200"}

## David

![](images/edavidaja.jpeg){width="25%"}

-   David Aja is a Solutions Engineer at Posit. Before joining Posit, he worked as a data scientist in the public sector.

## Gagan

![](images/gagan.png){width="25%"}

-   Gagandeep Singh is a former software engineer and data scientist who has worked in a variety of cross-technology teams before joining Posit as a Solutions Engineer.

## Michael

-   Michael Mayer is a Solutions Engineer at Posit.
:::

## Solutions Engineering at Posit

![](images/sol-eng.png){width="25%"}

-   Posit's Solutions Engineering team aims to shrink the distance between the needs of Posit's customers and our Pro and Open Source offerings, leading with curiosity and technical excellence.

-   Our customer-facing work helps our customers deploy, install, configure, and use our Pro products.

## Special Thanks to Alex Gold!

![](images/_40A8864.jpg){width="278" height="192"}

Author of [DevOps for Data Science](www.do4ds.com)

Posit Solutions Engineering Team Director

## Introduce yourself to your neighbor

Take 5 minutes and introduce yourself to your neighbors.

-   How do you think DevOps can help you in your work?

-   What are you most looking forward to in the conference?

## Word Cloud

![](images/Screenshot%202023-09-13%20at%201.49.45%20PM.png)


## Logistics & Workshop Setup {.toc-people-dark}

## Wifi

Name: Posit Conf 2023 Password: `conf2023`

#### üíª If your WIFI isn't working let us know as soon as possible!

## Pre-workshop Install

**Required**:\
<https://registry.hub.docker.com/signup>\
<https://github.com/signup>\

**Optional: (for local development)**\
<https://docs.docker.com/desktop/>\
<https://git-scm.com/book/en/v2/Getting-Started-Installing-Git>\
<https://quarto.org/docs/get-started/>\
<https://posit.co/downloads/>


## Workshop Install

+---------------------------+--------------------------------------+---------------------------------+
| Software                  | Link                                 | Credentials                     |
+===========================+======================================+=================================+
| Posit Workbench & Connect | <http://pos.it/class>                | Classroom ID: `DevOps_workshop` |
+---------------------------+--------------------------------------+---------------------------------+
| Docker Classroom          | <https://labs.play-with-docker.com/> | Docker Hub credentials          |
+---------------------------+--------------------------------------+---------------------------------+

## Documentation & Communication {.brackets-light}

All documents including slides are available on our website: <https://posit-conf-2023.github.io/DevOps/>

Discord channel - `DevOps-for-data-scientists`

Place a note on the back of your laptop

üü• - I need help

üü© - I'm done

## Daily Schedule {.brackets-light}

üìÖ September 17 and 18, 2023\
‚è∞ 09:00am - 5:00pm\
üè® ROOM: TBD\
‚úçÔ∏èTBD

| Time            | Topic |
|-----------------|-------|
| 10:30 - 11:00am | Break |
| 12:30 - 1:30pm  | Lunch |
| 3:00 - 3:30pm   | Break |

## Code of Conduct {.brackets-light}

<https://posit.co/code-of-conduct/>

You can report Code of Conduct violations in person, by email, or by phone.

## Workshop Goals

-   To understand how DevOps can help you in your work as data scientists

-   To understand the main principles and tools of DevOps

-   To get hands-on experience putting code into production using common DevOps workflows

-   To leave the workshop with some "assets" and skills you can use in your work

## Agenda & Lab Overview {.scrollable}

+------------------------------------+------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Section/Time                       | Topics                                               | Labs                                                                                                                                                          |
+====================================+======================================================+===============================================================================================================================================================+
| Part 1                             | Workshop overview                                    | Infrastructure & wifi setup                                                                                                                                   |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Logistics & setup                                    |                                                                                                                                                               |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Introductions                                        |                                                                                                                                                               |
+------------------------------------+------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Part 2: DevOps Principles & Tools  | Introduction to DevOps                               | Lab 1: Deploy your own Quarto website on Github Pages & Posit Connect using GitHub Actions \|                                                                 |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Version control & github                             |                                                                                                                                                               |
|                                    |                                                      |                                                                                                                                                               |
|                                    | CI/CD                                                |                                                                                                                                                               |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Reproducing workflows and environments               |                                                                                                                                                               |
+------------------------------------+------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Part 3: Docker for Data Scientists | How and why data scientists use docker in production | Lab #2: Write your own Dockerfile to deploy Open Source Shiny Server on [Docker playground](https://labs.play-with-docker.com/) and host an app on the server |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Docker: overview and architecture                    |                                                                                                                                                               |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Building docker images and containers                |                                                                                                                                                               |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Ports & networking                                   |                                                                                                                                                               |
+------------------------------------+------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Part 4: Data Science in Production | Choosing your deployment method                      | Lab #3: Host and secure an API on Posit Connect                                                                                                               |
|                                    |                                                      |                                                                                                                                                               |
|                                    | APIs and when to use them                            |                                                                                                                                                               |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Just enough auth                                     |                                                                                                                                                               |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Logging & metrics & testing                          |                                                                                                                                                               |
+------------------------------------+------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Part 5: Discussion                 | Course feedback                                      | Workshop Survey                                                                                                                                               |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Questions for the team                               |                                                                                                                                                               |
+------------------------------------+------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

## Supplemental Materials

https://

-   Linux
-   vim
-   Git
-   Cheat sheets

## Most important Linux commands {.smaller}

+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------+
| Command  | Description                                                                                                                                                                                                                                                                                                                                                                                | Examples                                                                             |
+==========+============================================================================================================================================================================================================================================================================================================================================================================================+======================================================================================+
| *cd*     | change directory                                                                                                                                                                                                                                                                                                                                                                           | https://linuxize.com/post/linux-cd-command/                                          |
+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------+
| *ls*     | list all files in current working directory;                                                                                                                                                                                                                                                                                                                                               | https://linuxize.com/post/how-to-list-files-in-linux-using-the-ls-command/           |
|          |                                                                                                                                                                                                                                                                                                                                                                                            |                                                                                      |
|          | add *-lha* flag for hidden files                                                                                                                                                                                                                                                                                                                                                           |                                                                                      |
+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------+
| *pwd*    | print working directory                                                                                                                                                                                                                                                                                                                                                                    | https://linuxize.com/post/current-working-directory/                                 |
+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------+
| *touch*  | create a file                                                                                                                                                                                                                                                                                                                                                                              | https://linuxize.com/post/linux-touch-command/                                       |
+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------+
| *mkdir*  | create a directory                                                                                                                                                                                                                                                                                                                                                                         | https://linuxize.com/post/how-to-create-directories-in-linux-with-the-mkdir-command/ |
+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------+
| *vim*    | open a file in Vim text editor                                                                                                                                                                                                                                                                                                                                                             | https://linuxize.com/post/how-to-save-file-in-vim-quit-editor/                       |
+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------+
| *curl*   | command-line utility for transferring data from or to a server. Uses one of the supported protocols including HTTP, HTTPS, [SCP](https://linuxize.com/post/how-to-use-scp-command-to-securely-transfer-files/) , [SFTP](https://linuxize.com/post/how-to-use-linux-sftp-command-to-transfer-files/) , and [FTP](https://linuxize.com/post/how-to-use-linux-ftp-command-to-transfer-files/) | https://linuxize.com/post/curl-command-examples/                                     |
+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------+
| *echo*   | print argument to standard output                                                                                                                                                                                                                                                                                                                                                          | https://linuxize.com/post/echo-command-in-linux-with-examples/                       |
+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------+
| *\$PATH* | environmental variable that includes colon-delimited list of directories where the shell searches for executable files                                                                                                                                                                                                                                                                     | https://linuxize.com/post/how-to-add-directory-to-path-in-linux/                     |
+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------+

## What we won't cover

-   How to become a DevOps engineer

-   Python-based workflows

-   In-depth security and auth practices


## Part 2: DevOps Principles & Tools {.toc-people-dark}

## Section Goals

-   To understand the main principles of DevOps and how they can improve data science workflows.

-   To get familiar with the DevOps toolkit.

-   To get familiar with how the `renv` package helps create reproducible environments for your R projects.

-   To get comfortable using the terminal for interacting with git and github.

-   To understand how to authenticate to github using SSH or HTTPS.

-   To practice creating a CI/CD workflow using yaml and Github Actions.

# "DevOps is a set of cultural norms, practices, and supporting tooling to help make the process of developing and deploying software smoother and lower risk."

::: footer
Definition credit:Alex Gold, https://www.do4ds.com
:::

::: notes
Let's get into it. We're at a DevOps workshop - so what is it. This is a best effort attempt by our very own Alex Gold, but its still a squishy broad buzz word that's defined differently across organization. Let's discuss how the concept of devops came about.
:::

## But first...a very brief history lesson

![](images/pheonix.webp){width="304"}

![](images/devops.jpg){width="200"}

::: notes
Reason for squishy definition is because it developed organically in the 2007-2009, across social media, twitter tag #devops was popular, online communities and became more organized through conferences, workshops, and grassroots attempts at implementation at diff companies. Then was introduced into larger companies like Intel, PayPal, Facebook.

Became more popular through work by Gene Kim and Patrick Debois and others - Pheonix Project is actually a novel about an IT project at a made-up company.

So what were all these people trying to do - what was the context? All trying to create something.
:::

## So you want to create an app?

![](images/mobius.png)

::: notes
Let's talk about what it looks like to create an application. On one side you had developers creating some sort of application - let's say a stock trading application, so your end user are stock traders

Devs would work on creating the code for this app, get requirements, test it and then package up all the source code in some way so that its executable and that it could be deployed somehow to those end users you'd configure the server, install any tools and frameworks needed to run the code, and then launch.

Now your stock traders are using their application - maybe they're giving feedback somehow or errors are being logged. Another team is monitoring the environment and seeing if servers are able to handle the load of all the users.

But eventually you'd need to fix bugs or release new features or maybe change things so that the app could handle more end users -

your dev team make updates, version those changes, test them, re-launch the app and you do this over and over again in some sort or release process -- so you have this continuous cycle of releasing your app, finding something to fix or add, testing that change, integrating that code, and then releasing the app..

Making this continuous process as fast, efficient, accurate, and low risk is the goal of devops.

sounds pretty efficient right -
:::

## Problems DevOps tries to solve

-   Siloed teams
-   Miscommunication
-   Slow & manual release cycles
-   Technical knowledge siloes
-   Incompatible systems or tech stacks
-   Opaque undocumented processes

::: notes
Unfortunately this isnt how it started. You want to make the release process as fast as possible but you also want it to be tested and free of bugs. And this introduces a natural conflict between speed and stability

So let's go back to the early aughts. You have the same goals of speed and accuracy - but this process of continuous integration, of testing, of automating processes so that your users can get their hands on the app - didnt exist.

One problem is that the entire process is siloed between the creation of the code and the deployment of your app. So your developers finish their code and then throw it over the fence to ops. Maybe they then throw it to security or to QA. But there was no formal alliance in place or processes on how the teams work together. Because each team is seemingly working on one part - the code vs. the deploy - there's also technical knowledge siloes - each team only knows their bit but not anything else.

So imagine this stock trading app - your developers are creating cool new features so that you can easily buy and sell stock, maybe even see data on whats happening in the market. But they're not necessarily thinking about how the app is secured or if its compliant with federal regulations or if user data is protected. Obvi this is a worst case scenario - but you get the picture.

So as the app is built it keeps getting thrown back and forth between the two teams and leads to one of the major problems that devops is trying to fix - really slow and manual bureaucratic release process.

On the technical side, a lot of the actual work is done manually. So you can imagine one team running tests manually in one environment - maybe the environment itself is created manually, or someone manually sizing up or fixing a server. This takes time, you need to get approval from people, and its not easily reproduced or really documented anywhere. Also, there is a lot of room for error and if things break its not easy to roll back bugs.

Problem becomes how do you automate this release process, make it streamlined, less error prone, improve how all these teams integrate and operate, and at the end of the day make the process of getting the app into the hands of your users much faster.
:::

## Common DevOps Principles

-   Collaboration

-   Continuous Integration & Delivery

-   Automation

-   Reproducibility

-   Culture change

::: notes
As the field of devops developed, there are different implementations/diff technologies of what devops means - these happen differently at different companies But there have been some common philosophies and best practices that have come out that I've seen consistently across the entire ecosystem.

First - **everyone** that's involved in the creation of this application should be collaborating and working together. This is my wink wink moment for you all of why devops is so important for data scientists

Then we have this concept of **Continuous Integration & Delivery** - we'll take about this in greater length in a few minutes - but this is the process of 1. the coding of the app 2. the versioning of that code is some kind of repository 3. testing those changes 4. integrating them into the app if those tests are passed 5. And then that continuous process of releasing those changes into production

So for the CI/CD process to work and specifically to work quickly - we will need some level of **automation** as we move through that cyclical process. You don't want to have to pause things to get approval or manually change things when tests pass - you want it to get to the user as quickly as possible after everything has been tested.

The next piece is reproducibility. You have different teams working on different pieces of the puzzle, but at the end of the day the end result is the same. Everyone is working on that same app - in this case our stock platform. So as jobs go from one team to another team and as your app goes from development to testing to finally your users, you want to make sure that there's a common ecoystem that everyone is working in. When you're testing your app you want to make sure that your environment is as similar to what is going to be in real-life or what is called "production". You also want to make sure that your code itself is reproducible and that it works for users regardless of their location or their computer or their browser maybe.

The last piece that I find really interesting is the concept of culture change. So what needs to change in your organization so that you're able to function while still holding this tension or conflict between speed and stability. How do you make sure that teams that have different incentives - for example security team vs. a data team - are able to work together.

So let me pause - that's a lot - everyone got a bit of a history lesson but as far as i'm aware no one here is a software developer or an IT engineer. So that brings me to this very important question: But
:::

## Why should we as data scientists care about this?

```{=html}
<iframe src="https://giphy.com/embed/f2ExpHhfiPJNceqORt" width="480" height="270" frameBorder="0" class="giphy-embed" allowFullScreen\>\</iframe\>
```
::: notes
lets have a little thought experiment
:::

## Has this ever happened to you?

::: columns
::: {.column width="50%"}
[You come back to code from a year ago and now it doesnt run!]{.fragment fragment-index="1"}
:::

::: {.column width="50%"}
[Reproducibility]{.fragment fragment-index="2" style="color: blue;"}
:::
:::

::: columns
::: {.column width="50%"}
[You need to hand off your model to the Engineering team but they only code in Java]{.fragment fragment-index="3"}
:::

::: {.column width="50%"}
[Continuous Integration & Delivery & Collaboration]{.fragment fragment-index="4" style="color: blue;"}
:::
:::

::: columns
::: {.column width="50%"}
[Your boss asks you to share that Shiny app with a client but the ops team is too busy working on their roadmap to help you deploy it somewhere.]{.fragment fragment-index="5"}
:::

::: {.column width="50%"}
[Culture Change]{.fragment fragment-index="6" style="color: blue;"}
:::
:::

## Why should data scientists/analysts care about DevOps?

::: incremental
-   Data scientists are developers!

-   Data science careers have moved from academic sphere to tech and software but education hasnt always followed

-   Automation, collaboration, testing can dramatically improve data work and improve reproducibility

-   The many hats of a data scientist

-   Improve collaboration & communication with other teams
:::

::: notes
spent a lot of time talking about teams working together to create a shared product. Data scientists are a part of that team. DS is a relatively new field and creating data-intensive apps is a huge part of tech world today.

DS career paths started in academia - not a lot of best practices are taught
:::

## Responsibility of the analyst

::: columns
::: {.column width="50%"}
![](images/Screenshot%202023-08-22%20at%203.26.22%20PM.png)
:::

::: {.column width="50%"}
![](images/Screenshot%202023-09-10%20at%2012.18.42%20PM.png)
:::
:::

::: notes
I mentioned before that a lot of DS comes from academia and research. So the concept of reproducing your results - especially if those results play a role in how medicines or medical devices are developed - is incredibly important.

2005 essay by John Ioannidis in scientific journal on what is known as the replicability crisis in scientific publishing, arguing that majority medical research studies cannot be replicated.

So as data scientists and we are curators of the data and are responsible for its legitimacy in many ways - obv cant always control it of course.

This second paper started looking a method of reproducing results - namely Jupyter notebooks - and found a lot of ways that reproducibility was improved but also a lot of places where things could have been done better and some best practices for how to do that - in what we call literate programming.

**27,271** Notebooks:

-   **11,454** could not declare dependencies

-   **5,429** could not successfully install declared dependencies

-   **9,185** returned an error when ran

-   **324** returned a different result than originally reported
:::

## From principles to tools

-   CI/CD
-   Environment Management
-   Package Management
-   Version Control & Git workflows
-   Automation Build tools
    -   YAML
    -   Dedicated cloud & CI/CD platforms
    -   Infrastructure as Code
    -   
-   Continuous Monitoring and testing

::: notes
build tools for automating workflows, creating configurations for those workflows, and tools to reproduce environments consistently across workflows

discuss these very very briefly
:::

## The CI/CD Pipeline

![](images/cicd.png)

::: notes
-   an iterative cycle of small steps to quickly build, test, and deploy your code -CI/CD is a critical component tof making DevOps happen. -CI/CD comprises of an iterative cycle continuous integration and continuous delivery or continuous deployment. -Put together, they form a "CI/CD pipeline"---a series of automated workflows that help DevOps teams cut down on manual tasks:

-Continuous integration (CI) automatically builds, tests, and commit code changes into a shared repository; Developer writes code and commits to a repo like github. This triggers an automatic process where the code is built, tested and then either passes or fails.

-Continuous delivery (CD) delivers code changes to production-ready environments for approval; final step is sometimes manual

-Continuous deployment (CD) automatically deploys code changes to customers directly. All code based - not manual
:::

## Environment Management {.smaller}

::: notes
Content is deployed (and code is promoted) across different environments with different intended audiences.
:::

+-----------------------------------------------------------------------+--------------------------------------------------------------------------+--------------------------------+
| Dev                                                                   | Test                                                                     | Prod                           |
+=======================================================================+==========================================================================+================================+
| a place for data scientists to do exploratory analysis and experiment | as similar to prod as possible                                           | separate from dev and test     |
|                                                                       |                                                                          |                                |
| often just your local desktop                                         | code testing                                                             | created using code             |
|                                                                       |                                                                          |                                |
| data science "sandbox" with data that's as close to real as possible  | data validation                                                          | code promotion process + tests |
|                                                                       |                                                                          |                                |
| access to R/Python packages                                           | in software dev world includes integration, unit, and regression testing | completely automatic           |
+-----------------------------------------------------------------------+--------------------------------------------------------------------------+--------------------------------+

## Version Control & Workflows

![](images/Screenshot%202023-08-23%20at%2011.20.04%20AM.png)

::: notes
Version control is a main tool for Continuous Integration -

lots of variants - giit, github., svn, gitlab, etc

distributed version control - everyone has their own repo

can track changes and roll them back

can fix merge conflicts

an an iterative process to build, test, collaborate on your code to above environments. Very commonly, individuals work on separate branches that are then tested and reviewed by colleagues before they are merged into a main branch.

In addition to the action of promoting your code - its also important to have processes in place for how it happens code reviews, process for your team, how to name things, pull requests, version control with git, feature branching, automatic tests
:::

## Lab Activity

üü• - I need help

üü® - I'm still working

üü© - I'm done

Login to pos.it/class with code `conftest` and create an account with your name and email

Complete Part 1 of Lab - add link

## Reproducing your environment

What are the layers that need to be reproduced across your dev, test, and prod environments?

In your day-to-day work, what's the hardest reproducibility challenge?

## Layers of reproducibility

+---------------+---------------------------------+
| Layer         | Contents                        |
+===============+=================================+
| Code          | scripts, configs, applications  |
+---------------+---------------------------------+
| Packages      | R + Python Packages             |
+---------------+---------------------------------+
| System        | R + Python Language Versions    |
|               |                                 |
|               | System Libraries                |
|               |                                 |
|               | Operating System + dependencies |
+---------------+---------------------------------+
| Hardware      | Virtual Hardware                |
|               |                                 |
|               | Physical Hardware               |
+---------------+---------------------------------+

::: notes
-   Let's say someone wanted to reproduce your project including your code and your environment. Make a list of the layers that would need to be reproduced on their machine. (For example, a layer would be the version of R that you're using)

options("repos") Run .libPaths()

-   Hints:

    -   Inspect your renv.lock file.
    -   Where are your packages being pulled from? Confirm by typing `options("repos")`.
        -   You can modify your package repository by running `options("repos" = c("<REPO-NAME>" = "https://your-repository-url.com"))` in your RStudio console.
    -   Visit the webpage where packages are being pulled from and see if you can identify package dependencies. Are packages downloaded as binaries or from source?
    -   What are your server and OS dependencies? (If you are not sure which distribution of Linux you are using, you can find it by typing `cat /etc/*-release` in your terminal)
:::

## Mechanisms for reproducibility

\*\* make this a diagram starting from least to most reproducibility

-   documenting state & version control

-   virtual environments (`renv`, `venv`) + package management

-   Containerization & docker

-   Infrastructure as Code

## Packages vs. Libraries vs. Repositories

**Package** - contains code, functions, data, and documentation.

**Library** - is a directory where packages are installed.

**Repository** - a collection of packages. CRAN is a public external repository that is a network of servers that distribute R along with R packages.

::: notes
packages - Can be be distributed as SOURCE (a directory with all package components), [BINARIES](https://solutions.posit.co/envs-pkgs/environments/repositories/index.html#binary-packages) (contains files in OS-specific format) or as a BUNDLE (compressed file containing package components, similar to source).

library - You can have user-level or project-level libraries. Run `.libPaths()` to see yours. To use a package in has to be installed in a library with `install.packages()` and then loaded into memory with `library(x)` .

repo - others include pypi, bioconducter, private repos
:::

## Renv workflow

![](images/Screenshot%202023-09-06%20at%208.31.22%20PM.png)

::: notes
1.  Use a version control system e.g.[git](https://git-scm.com/) with [GitHub](https://github.com/)

2.  One user (perhaps yourself) should explicitly initialize `renv` in the project, via [`renv::init()`](https://rstudio.github.io/renv/reference/init.html). This will create the initial `renv` lockfile, and also write the `renv` auto-loaders to the project's `.Rprofile` and `renv/activate.R`. These will ensure the right version of `renv` is downloaded and installed for your collaborators when they start in this project.

3.  Using a branching strategy push your code alongside the generated lockfile `renv.lock`. Be sure to also share the generated auto-loaders in `.Rprofile` and `renv/activate.R`.

4.  When a collaborator first launches in this project, `renv` should automatically bootstrap itself, thereby downloading and installing the appropriate version of `renv` into the project library. After this has completed, they can then use [`renv::restore()`](https://rstudio.github.io/renv/reference/restore.html) to restore the project library locally on their machine.
:::

## Example

``` {.libpaths()}
# install.packages("renv")
renv::init()
renv::snapshot()
lapply(.libPaths(), list.files)
```

::: footer
üîç Live code
:::

## Lab Activity

üü• - I need help

üü® - I'm still working

üü© - I'm done

Complete Part 2 of Lab: Deploy Quarto with GHA including the exercises

## Build tools

::: notes
tools that automate the process of building and deploying your code once it goes from your dev env to test and prod

Tools include config files, `config` package, CI/CD software such as GHA, automatic tests
:::

![](images/Screenshot%202023-08-23%20at%202.49.21%20PM.png)

::: footer
Illustration credit:
:::

## Power of YAML

-   YAML Ain't Markup Language

-   communication of data between people and computers.

-   human friendly

-   everything is a key value pair and interpreted as maps or dictionaries

-   used for configuration files across many execution environments including Docker, virtual machines, K8s, helm, IaaS, etc

## XML

```         
<?xml version="1.0"?>
<EmpRecord>
<Employee id="emp01">
<name>Alex</name>
<job>Developer</job>
<skills>python, C/C++, paskal</skills>
</Employee>
 
<Employee id="emp02">
<name>Bob</name>
<job>Tester</job>
<skills>lips, forton, REST APIs</skills>
</Employee>
 
</EmpRecord>
```

## JSON

```         
{
"EmpRecord": {
"Employee": [
{
"-id": "emp01",
"name": "Alex",
"job": "Developer",
"skills": "python, C/C++, paskal"
},
{
"-id": "emp02",
"name": "Bob",
"job": "Tester",
"skills": "lips, forton, REST APIs"
}
]
}
}
```

## YAML

```         
EmpRecord:  
  emp01:
    name: Alex
    job: Developer
    skills: python, C/C++, paskal
  emp02:
    name: Bob
    job: Tester
    skills: lips, forton, REST APIs
```

## YAML syntax

-   whitespace indentation is used to denote structure, no need for quotes nor brackets

-   Colons separate keys and their values

-   Dashes are used to denote a list

https://github.com/sd031/yaml-crash-course/blob/main/full_example.yaml

## Examples

-   https://github.com/rstudio/rstudio-docker-products/blob/dev/docker-compose.yml
-   https://github.com/Rikagx/personal-website/blob/main/.github/workflows/publish.yaml

::: footer
üîç Live code
:::

## Lab Activity

üü• - I need help

üü® - I'm still working

üü© - I'm done

Inspect your \_quarto.yml file and identify what each part of it does using the quarto site.

## Is version control secure?

-   our code is still saved locally
-   How do we make sure that the code we push to Github (or elsewhere) is secure?

## A short auth teaser

-   We can use a variety of data sharing "transfer protocols"
-   protocols specify what kind of traffic is moving between 2 machines
-   a port specifies where to direct the traffic

![](images/Screenshot%202023-09-07%20at%209.28.32%20AM.png)

::: notes
whether its email, text, files, etc A port is a virtual point where network connections start and end. Ports are software-based and managed by a computer's operating system. Ports allow computers to easily differentiate between different kinds of traffic: emails go to a different port than webpages, for instance, even though both reach a computer over the same Internet connection.
:::

## Git protocol options

| http    | https    | SSH     |
|---------|----------|---------|
| port 80 | port 443 | port 22 |

http - text sent over the internet

https - http encrypted with "SSL/TLS"

SSH - secure shell

::: notes
hypertext transfer protocol When a web user wants to load or interact with a web page, their web browser sends an HTTP request to the origin server that hosts the website's files. These requests are essentially lines of text that are sent via the internet.

https : http encrypted with SSL/TLS - digital certificates that establish an encrypted connected

SSH: secure shell, public-key cryptography to authenticate the client, used for remote logins, command line execution

HTTPS is simpler. For most services besides Github, you just have to enter in your username and password, and you'll be able to push and pull code.

You don't have to juggle multiple SSH keys around to use multiple devices.

Port 443, which HTTPS uses, is open in basically any firewall that can access the internet. That isn't always the case for SSH.

The primary downside for most people is that you must enter your Git password/token every time you push. While it gets added to a cache, it's not configured to cache permanently (though this can be changed). With SSH keys, it just uses the key file on disk every time.

Where SSH takes the lead is with the authentication factor---the key. The length of it alone makes it harder to accidentally leak, and due to it being unwieldy and unique, it's generally more secure.
:::

## Which one should I use

::: columns
::: {.column width="50%"}
https - simpler - username and password or PAT - have to either cache credentials or enter in every time. can be used with Github REST API
:::

::: {.column width="50%"}
SSH - potentially more secure - uses key for auth - created per machine once
:::
:::

## Port Examples

![](images/ports-01.jpg)

::: notes
Each port is associated with a specific process or service.

show ping localhost
:::

## Lab Activity

üü• - I need help

üü® - I'm still working

üü© - I'm done

Part 3 of Lab: Deploy Quarto with GHA including the exercises

::: notes
show first part

git config --list git config --global user.name "Your Name" git config --global user.email "youremail\@yourdomain.com"
:::

## Automation Build Tools

-   GHA is one tool to automate developer workflows
-   CI/CD is just one example of these workflows
-   Runs on github servers
-   Uses yaml

![](images/Screenshot%202023-09-10%20at%201.32.42%20PM.png)

::: notes
-   A github action allows us to create workflows that are triggered by a github action such as a push or pull to a branch

-   Build tools + version control in on system

-   Parts of a GHA - trigger, job, steps

-   Workflows can include tests, markdown renders, shell scripts, cron jobs, or deployments. They can be as simple or as complicated as you need. Open-source community provides a ton of examples of actions.

-   Open source collection of "available" actions

1.  In the previous exercise we created a repo - we can use it to see what kind of actions we can create

https://github.com/Rikagx/workshop_testing/blob/master/.github/workflows/publish.yaml

github.com/actions

https://github.com/r-lib/actions
:::

## Actions Ecosystem

github.com/actions

github.com/r-lib/actions

https://github.com/Rikagx/ssh_testing/actions/new

## Syntax {.smaller}

```         
name: My Workflow
on:
  push:
    branches:
      - releases
env:
  my_token: ${{ secrets.GITHUB_TOKEN }}
jobs:
  job_1:
    runs-on: ubuntu-latest
    steps:
      - name: Checking out our code
        uses: actions/checkout@master
      - name: Say something
        run: |
          echo "A little less ${message}"
          echo "A little more action"
  job_2:
    needs: job_1
    container:
      image: node:10.16
      env:
        NODE_ENV: development
      ports:
        - 80
      volumes:
        - my_docker_volume:/volume_mount
      options: --cpus 1
```

## Lab Activity

üü• - I need help

üü® - I'm still working

üü© - I'm done

Part 4 of Lab: Deploy Quarto with GHA including the exercises

## Part 3 Goals: Docker for Data Scientists

-   to understand different docker workflows
-   to learn common docker syntax for building and running containers
-   to get hands on experience building and running containers
-   to explore the linux file system

## Introduction to Docker

-   Open-source tool.
-   Package applications and its dependencies in a unit called a container.
-   Create isolated environments for different experiments.
-   Share work with colleagues without environment setup issues.

::: notes
Docker is a tool that allows you to virtualize (put your computer in the cloud) everything you need to create an application or in this case a data science product You can share containers with colleagues without requiring them to have to set up their own local machines Without something like this, in order to recreate or test code that someone else wrote, you'd need every developer to download the same dependencies, configurations, scripts and make sure that it ran on their machine - whether thats a mac, or windows, or linux or some other operating system
:::

## Lifecycle

Dockerfile - script of instruction to build an image

Image - read-only instructions that build everything you need to run an application. Made up of layers

Container - isolated instance of a running image

Image Registry - repository for images

![](images/lifecycle.png)

::: footer
Illustration credit: Alex Gold, do4ds.com
:::

## How do data scientists use docker?

## Docker as testing environment

![](images/Screenshot%202023-09-12%20at%209.49.46%20AM.png)

## Example

``` bash
docker pull postgres:12
docker pull postgres:latest
docker container ls -a
docker run -d -e POSTGRES_PASSWORD=mysecretpassword --name postgres_early imageID
docker run -d -e POSTGRES_PASSWORD=mysecretpassword --name postgres_new imageID
docker container ls -a
docker stop
docker restart
```

::: footer
üîç Live code
:::

::: notes
a dockerfile is the recipe to build a docker images this recipe is stored in some sort of repository, this can be private, public, or dockerhub - which is the default a docker image contains lightweight instructions to create your application. Docker images use something called layers which makes it super easy and quick to update. Layers start at a base layer which is usually the linux operating system and then they go up to the application layer. a container is the environment for a running process of an image - so if an image is running then its using a container instance. You can have multiple containers running at the same time. But once you delete it everything inside of it goes away.

Let's see an example of what this looks like in practice. Lets say we need to use a postgres sql database for some testing - but we want to test using an older and a newer version of postgres.

Lets go to Dockerhub and search for it. We can see official images but there are also thousands of them created by people- hub only has images not dockerfiles or containers themselves. docker image ls - lets list all the images that we have docker pull postgres:12 - see how its pulling and extracting all these layers - but what if we want a newer version or what if we need to run both versions on our machine

docker pull postgres:latest - notice how some of these layers already exist so it takes a lot less time

Lets go on dockerhub and see if we can understand a bit more about the layers https://hub.docker.com/layers/library/postgres/12/images/sha256-a97fd76ab09599e2ddc15c90a87f9a4a2a60551d99f8e7397f12a1d606d7f0ab?context=explore -

we can see that there are a lot of layers but its hard to understand what exactly is happening - lets look at the dockerfile that shows us the recipe for postgres - this is usually saved in a [github](https://github.com/docker-library/docs/blob/master/postgres/README.md) repo - not on dockerhub which is just images

every docker file starts with a from command - this is the base layers that starts the image, then we are running some things, copying , env variables, and starting

lets run the image and see
:::

## Docker as development environment

![](images/Screenshot%202023-09-12%20at%2010.00.41%20AM.png)

## Example

```         
# pull the image
docker pull rocker/rstudio:4.2.2

# run container
docker run --rm \
           -p 8888:8787 \
           -e PASSWORD=password \
           rocker/rstudio:4.2.2
```

## Docker as a portable app (in production)

![](images/shiny.png){width="74"}

![](images/plumber.png){width="74"}

![](images/bookdown.png){width="74"}

![](images/tidymodels.png){width="74"}

## Example

![](images/Screenshot%202023-09-12%20at%2010.14.39%20AM.png)

## Docker for CI/CD

![](images/docker_ci.png)

## Example

```         
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Login to Docker Hub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}
      -
        name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
      -
        name: Build and push
        uses: docker/build-push-action@v4
        with:
          context: .
          file: ./Dockerfile
          push: true
          tags: ${{ secrets.DOCKERHUB_USERNAME }}/latest
```

::: notes
-   Data scientists benefit from Docker's consistency and reproducibility.

-   Create isolated environments for different experiments.

-   Share work with colleagues without environment setup issues.

-   **Consistency:** Containers ensure that applications run the same way across different environments.

-   **Isolation:** Containers isolate applications and their dependencies, preventing conflicts.

-   **Portability:** Containers can run on any system that supports Docker, reducing "it works on my machine" issues.
:::

## Docker as a platform

![](images/shiny-01.png){width="100"}

![](images/rsconnect.png){width="100"}

## Example

```         
docker run -d -p 3838:3838 rocker/shiny
```

## Virtual Machine vs. Container

![](images/Screenshot%202023-09-03%20at%209.56.54%20AM.png)

::: notes
containers are very lightweight which makes it really easy and quick to spin them up

this is because the container itself doesnt have a host operating system or any hardware - intel chip, apple chip etc - this is in the docker engine or runtime which we will look at in the architecture
:::

## Docker Architecture

![](images/Screenshot%202023-08-30%20at%2011.31.56%20AM.png)

::: notes
-   Docker uses a client-server architecture. The Docker client talks to the Docker daemon.

-   The Docker client - is the primary way that users interface with Docker via CLI

-   The Docker daemon does the heavy lifting of building, running, and distributing your Docker containers

-   The Docker client and daemon can run on the same system, or you can connect a Docker client to a remote Docker daemon. The Docker client and daemon communicate using a REST API, over UNIX sockets or a network interface.

-   Registry is a Repository for Docker images (e.g., Docker Hub) where you can store and share images.

-   Docker engine is a container runtime that runs on diffrent OS's. Set up the isolated environment for your container
:::

## Mode for running containers

+------------------------------------------------------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Mode                                                       | Run command       | Use case                                                                                                                                                                                                           |
+============================================================+===================+====================================================================================================================================================================================================================+
| Detached                                                   | `docker run -d`   | This runs the container in the **background** so the container keeps running until the application process exits, or you stop the container. Detached mode is often used for production purposes.                  |
+------------------------------------------------------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Interactive + terminal                                     | `docker run -it`  | This runs the container in the **foreground** so you are unable to access the command prompt. Interactive mode is often used for development and testing.                                                          |
+------------------------------------------------------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Remove everything once the container is done with its task | `docker run --rm` | This mode is used on foreground containers that perform **short-term tasks** such as tests or database backups. Once it is removed anything you may have downloaded or created in the container is also destroyed. |
+------------------------------------------------------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

## Lab Activity

üü• - I need help

üü® - I'm still working

üü© - I'm done

Complete Lab 2: Part 1

## Container Debugging

-   Interactive mode

-   `docker exec`

-   Logging

```         
docker run -it -d ubuntu
docker container ls -a 
docker exec -it CONTAINER_ID bash

docker container run -d --name mydb \
 --name mydb \
 -e MYSQL_ROOT_PASSWORD=my-secret-pw \ 
 mysql
 
 docker container logs mydb
```

::: footer
üîç Live code
:::

## Lab Activity

üü• - I need help

üü® - I'm still working

üü© - I'm done

Complete Lab 2: Part 2

## Port Mapping with `docker run -p`

```         
docker pull httpd:alpine
docker pull httpd:latest

docker inspect --format='{{.Config.ExposedPorts}}' httpd:latest
docker inspect --format='{{.Config.ExposedPorts}}' httpd:alpine

docker run -p DockerHostPort:ApplicationPort

docker run -d -p 81:80 --name httpd-latest httpd:latest
curl http://localhost:81

docker run -d -p 80:80 --name httpd-alpine httpd:alpine
curl http://localhost:80
```

::: footer
üîç Live code
:::

## Persisting data with Docker

-   State is persistent information that is recorded and recalled later

-   Containers are designed to be ephemeral e.g. stateless by default

-   Data applications are usually stateful and more complex to deploy

## Docker examples

-   volume mount

-   bind mount

-   external storage

-   shared file system

## Putting it all together

https://github.com/rstudio/rstudio-docker-products/blob/dev/docker-compose.yml

::: notes
-   **docker-compose:** A tool for defining and running multi-container Docker applications.
-   Uses a YAML file to define services, networks, and volumes.
-   Simplifies the orchestration of complex applications.
:::

## Lab Activity

üü• - I need help

üü® - I'm still working

üü© - I'm done

Complete Lab 2: Part 3 Complete Lab 2: Part 4

## Building Docker Images

-   Images are build using a Dockerfile or interactively "on-the-fly"

-   Steps to version and share your images on Dockerhub (or a different repository)

make this a diagram Step 1: Commit Step 2: Tag Step 3: Push

## Lab Activity

üü• - I need help

üü® - I'm still working

üü© - I'm done

Complete Lab 2: Part 5

## Dockerfile Build Commands

| Command | Description |
|---------|-------------|
| FROM    |             |
| ENV     |             |
| COPY    |             |
| RUN     |             |
|         |             |
|         |             |
|         |             |

## Dockerfile Example

Walk through Posit Connect [Dockerfile](https://github.com/rstudio/rstudio-docker-products/blob/dev/connect/Dockerfile.ubuntu2204)

## Activity

Complete Lab 2: Part 6

## Part 4: Data Science in Production

## Data Science in Production {.content-dark}

-   Presentation Layer

-   Processing Layer

-   Data store Layer

## Choosing the right presentation layer

-   [Alex's flow chart](https://do4ds.com/chapters/sec1/1-2-proj-arch.html)

-   credit text

## Choosing an API

![](images/apis.png)

## Production "State"

Questions to ask once your content is able to be consumed by your intended audience

-   Where is it deployed?

-   Is it secure and accessible?

-   Is it maintainable?

-   Does it scale?

-   Is your code efficiently written?

-   Is it tested?

## Where is it deployed?

list of PaaS / Caas and highlight Connect

## Lab Activity:

üü• - I need help

üü® - I'm still working

üü© - I'm done

Part 1: Host API on Posit Connect

## Is it secure?

-   Basic Auth

-   API keys

-   Token-based

## Securing credentials

-   username and password

-   centralized credential server

-   SSO

## Is it accessible?

RBAC

## Lab Activity:

üü• - I need help

üü® - I'm still working

üü© - I'm done

Part 2:

## Is it maintainable

git-backed deploymnet

## Is it scalable?

scaling up vs. scaling out

connect shiny resource options

## Is your code efficient?

-   data storage

-   computations

-   caches

## Is it tested

testing as part of CI/CD

## 
