---
title: "DevOps for Data Scientists"
subtitle: "wifi"
title-slide-attributes: 
  data-background-color: white
  data-background-image: _extensions/positconfslides/assets/backgrounds/toc-light.svg
  data-background-size: contain
format:
  positconfslides-revealjs: 
    chalkboard: true
    slide-number: true
    footer: <https://github.com/posit-conf-2023/DevOps>
    incremental: false
    code-copy: true
    center-title-slide: false
    code-link: true
    code-overflow: wrap
    highlight-style: a11y
    width: "1600"
    height: "900"
    filters:
      - positconfslides
---

## Part 1: Introductions, setup, & workshop overview {.toc-people-dark}

## Meet your instructors

::: panel-tabset
## Rika

![](images/rika_bio-01.jpeg){width="25%"}

-   Solutions Engineer at Posit

-   Former Data Scientist and Data Engineer

## Andrie

![](images/Andrie%20square%20500px.jpg){width="200"}

## David

![](images/edavidaja.jpeg){width="25%"}

-   David Aja is a Solutions Engineer at Posit. Before joining Posit, he worked as a data scientist in the public sector.

## Gagan

![](images/gagan.png){width="25%"}

-   Gagandeep Singh is a former software engineer and data scientist who has worked in a variety of cross-technology teams before joining Posit as a Solutions Engineer.

## Michael

-   Michael Mayer is a Solutions Engineer at Posit.
:::

## Solutions Engineering at Posit

![](images/sol-eng.png){width="25%"}

-   Posit's Solutions Engineering team aims to shrink the distance between the needs of Posit's customers and our Pro and Open Source offerings, leading with curiosity and technical excellence.

-   Our customer-facing work helps our customers deploy, install, configure, and use our Pro products.

## Special Thanks to Alex Gold!

![](images/_40A8864.jpg){width="278" height="192"}

Author of [DevOps for Data Science](www.do4ds.com)

Posit Solutions Engineering Team Director

## Introduce yourself to your neighbor

Take 5 minutes and introduce yourself to your neighbors.

-   How do you think DevOps can help you in your work?

-   What are you most looking forward to in the conference?

## Word Cloud

![](images/Screenshot%202023-09-13%20at%201.49.45%20PM.png)

## Logistics & Workshop Setup {.toc-people-dark}

## Wifi

Name: Posit Conf 2023 Password: `conf2023`

#### üíª If your WIFI isn't working let us know as soon as possible!

## Pre-workshop Install

**Required**:\
<https://registry.hub.docker.com/signup>\
<https://github.com/signup>\

**Optional: (for local development)**\
<https://docs.docker.com/desktop/>\
<https://git-scm.com/book/en/v2/Getting-Started-Installing-Git>\
<https://quarto.org/docs/get-started/>\
<https://posit.co/downloads/>

## Workshop Install

+---------------------------+--------------------------------------+---------------------------------+
| Software                  | Link                                 | Credentials                     |
+===========================+======================================+=================================+
| Posit Workbench & Connect | <http://pos.it/class>                | Classroom ID: `DevOps_workshop` |
+---------------------------+--------------------------------------+---------------------------------+
| Docker Classroom          | <https://labs.play-with-docker.com/> | Docker Hub credentials          |
+---------------------------+--------------------------------------+---------------------------------+

## Documentation & Communication {.brackets-light}

All documents including slides are available on our website: <https://posit-conf-2023.github.io/DevOps/>

Discord channel - `DevOps-for-data-scientists`

Place a note on the back of your laptop

üü• - I need help

üü© - I'm done

## Daily Schedule {.brackets-light}

üìÖ September 17 and 18, 2023\
‚è∞ 09:00am - 5:00pm\
üè® ROOM: TBD\
‚úçÔ∏èTBD

| Time            | Topic |
|-----------------|-------|
| 10:30 - 11:00am | Break |
| 12:30 - 1:30pm  | Lunch |
| 3:00 - 3:30pm   | Break |

## Code of Conduct {.brackets-light}

<https://posit.co/code-of-conduct/>

You can report Code of Conduct violations in person, by email, or by phone.

## Workshop Goals

-   To understand how DevOps can help you in your work as data scientists

-   To understand the main principles and tools of DevOps

-   To get hands-on experience putting code into production using common DevOps workflows

-   To leave the workshop with some "assets" and skills you can use in your work

## Agenda & Lab Overview {.scrollable}

+------------------------------------+------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Section/Time                       | Topics                                               | Labs                                                                                                                                                          |
+====================================+======================================================+===============================================================================================================================================================+
| Part 1                             | Workshop overview                                    | Infrastructure & wifi setup                                                                                                                                   |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Logistics & setup                                    |                                                                                                                                                               |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Introductions                                        |                                                                                                                                                               |
+------------------------------------+------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Part 2: DevOps Principles & Tools  | Introduction to DevOps                               | Lab 1: Deploy your own Quarto website on Github Pages & Posit Connect using GitHub Actions \|                                                                 |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Version control & github                             |                                                                                                                                                               |
|                                    |                                                      |                                                                                                                                                               |
|                                    | CI/CD                                                |                                                                                                                                                               |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Reproducing workflows and environments               |                                                                                                                                                               |
+------------------------------------+------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Part 3: Docker for Data Scientists | How and why data scientists use docker in production | Lab #2: Write your own Dockerfile to deploy Open Source Shiny Server on [Docker playground](https://labs.play-with-docker.com/) and host an app on the server |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Docker: overview and architecture                    |                                                                                                                                                               |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Building docker images and containers                |                                                                                                                                                               |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Ports & networking                                   |                                                                                                                                                               |
+------------------------------------+------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Part 4: Data Science in Production | Choosing your deployment method                      | Lab #3: Host and secure an API on Posit Connect                                                                                                               |
|                                    |                                                      |                                                                                                                                                               |
|                                    | APIs and when to use them                            |                                                                                                                                                               |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Just enough auth                                     |                                                                                                                                                               |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Logging & metrics & testing                          |                                                                                                                                                               |
+------------------------------------+------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Part 5: Discussion                 | Course feedback                                      | Workshop Survey                                                                                                                                               |
|                                    |                                                      |                                                                                                                                                               |
|                                    | Questions for the team                               |                                                                                                                                                               |
+------------------------------------+------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+

## Supplemental Materials

https://

-   Linux
-   vim
-   Git
-   Cheat sheets

## Most important Linux commands {.smaller}

+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------+
| Command  | Description                                                                                                                                                                                                                                                                                                                                                                                | Examples                                                                             |
+==========+============================================================================================================================================================================================================================================================================================================================================================================================+======================================================================================+
| *cd*     | change directory                                                                                                                                                                                                                                                                                                                                                                           | https://linuxize.com/post/linux-cd-command/                                          |
+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------+
| *ls*     | list all files in current working directory;                                                                                                                                                                                                                                                                                                                                               | https://linuxize.com/post/how-to-list-files-in-linux-using-the-ls-command/           |
|          |                                                                                                                                                                                                                                                                                                                                                                                            |                                                                                      |
|          | add *-lha* flag for hidden files                                                                                                                                                                                                                                                                                                                                                           |                                                                                      |
+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------+
| *pwd*    | print working directory                                                                                                                                                                                                                                                                                                                                                                    | https://linuxize.com/post/current-working-directory/                                 |
+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------+
| *touch*  | create a file                                                                                                                                                                                                                                                                                                                                                                              | https://linuxize.com/post/linux-touch-command/                                       |
+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------+
| *mkdir*  | create a directory                                                                                                                                                                                                                                                                                                                                                                         | https://linuxize.com/post/how-to-create-directories-in-linux-with-the-mkdir-command/ |
+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------+
| *vim*    | open a file in Vim text editor                                                                                                                                                                                                                                                                                                                                                             | https://linuxize.com/post/how-to-save-file-in-vim-quit-editor/                       |
+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------+
| *curl*   | command-line utility for transferring data from or to a server. Uses one of the supported protocols including HTTP, HTTPS, [SCP](https://linuxize.com/post/how-to-use-scp-command-to-securely-transfer-files/) , [SFTP](https://linuxize.com/post/how-to-use-linux-sftp-command-to-transfer-files/) , and [FTP](https://linuxize.com/post/how-to-use-linux-ftp-command-to-transfer-files/) | https://linuxize.com/post/curl-command-examples/                                     |
+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------+
| *echo*   | print argument to standard output                                                                                                                                                                                                                                                                                                                                                          | https://linuxize.com/post/echo-command-in-linux-with-examples/                       |
+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------+
| *\$PATH* | environmental variable that includes colon-delimited list of directories where the shell searches for executable files                                                                                                                                                                                                                                                                     | https://linuxize.com/post/how-to-add-directory-to-path-in-linux/                     |
+----------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------+

## What we won't cover

-   How to become a DevOps engineer

-   Python-based workflows

-   In-depth security and auth practices

## Part 2: DevOps Principles & Tools {.toc-people-dark}

## Section Goals

-   To understand the main principles of DevOps and how they can improve data science workflows.

-   To get familiar with the DevOps toolkit.

-   To get familiar with how the `renv` package helps create reproducible environments for your R projects.

-   To get comfortable using the terminal for interacting with git and github.

-   To understand how to authenticate to github using SSH or HTTPS.

-   To practice creating a CI/CD workflow using yaml and Github Actions.

# "DevOps is a set of cultural norms, practices, and supporting tooling to help make the process of developing and deploying software smoother and lower risk."

::: footer
Definition credit:Alex Gold, https://www.do4ds.com
:::

::: notes
Let's get into it. We're at a DevOps workshop - so what is it. This is a best effort attempt by our very own Alex Gold, but its still a squishy broad buzz word that's defined differently across organization. Let's discuss how the concept of devops came about.
:::

## But first...a very brief history lesson

![](images/pheonix.webp){width="304"}

![](images/devops.jpg){width="304"}

::: notes
Reason for squishy definition is because it developed organically in the 2007-2009, across social media, twitter tag #devops was popular, online communities and became more organized through conferences, workshops, and grassroots attempts at implementation at diff companies. Then was introduced into larger companies like Intel, PayPal, Facebook.

Became more popular through work by Gene Kim and Patrick Debois and others - Pheonix Project is actually a novel about an IT project at a made-up company.

So what were all these people trying to do - what was the context? All trying to create something.
:::

## So you want to create an app?

![](images/mobius.png)

::: notes
Let's talk about what it looks like to create an application. On one side you had developers creating some sort of application - let's say a stock trading application, so your end user are stock traders

Devs would work on creating the code for this app, get requirements, test it and then package up all the source code in some way so that its executable and that it could be deployed somehow to those end users you'd configure the server, install any tools and frameworks needed to run the code, and then launch.

Now your stock traders are using their application - maybe they're giving feedback somehow or errors are being logged. Another team is monitoring the environment and seeing if servers are able to handle the load of all the users.

But eventually you'd need to fix bugs or release new features or maybe change things so that the app could handle more end users -

your dev team make updates, version those changes, test them, re-launch the app and you do this over and over again in some sort or release process -- so you have this continuous cycle of releasing your app, finding something to fix or add, testing that change, integrating that code, and then releasing the app..

Making this continuous process as fast, efficient, accurate, and low risk is the goal of devops.

sounds pretty efficient right -
:::

## Problems DevOps tries to solve

-   Siloed teams
-   Miscommunication
-   Slow & manual release cycles
-   Technical knowledge siloes
-   Incompatible systems or tech stacks
-   Opaque undocumented processes

::: notes
So this is the idealized example - but what was it like in practice 20 years ago. You want to make the release process as fast as possible but you also want it to be tested and free of bugs. And this introduces a natural conflict between speed and stability

You have the same goals of speed and accuracy - but this process of continuous integration, of testing, of automating processes so that your users can get their hands on the app - didnt exist.

One problem is that the entire process is siloed between the creation of the code and the deployment of your app. So your developers finish their code and then throw it over the fence to ops. Maybe they then throw it to security or to QA. But there was no formal alliance in place or processes on how the teams work together. Because each team is seemingly working on one part - the code vs. the deploy - there's also technical knowledge siloes - each team only knows their bit but not anything else.

So imagine this stock trading app - your developers are creating cool new features so that you can easily buy and sell stock, maybe even see data on whats happening in the market. But they're not necessarily thinking about how the app is secured or if its compliant with federal regulations or if user data is protected. Obvi this is a worst case scenario - but you get the picture.

So as the app is built it keeps getting thrown back and forth between the two teams and leads to one of the major problems that devops is trying to fix - really slow and manual bureaucratic release process.

On the technical side, a lot of the actual work is done manually. So you can imagine one team running tests manually in one environment - maybe the environment itself is created manually, or someone manually sizing up or fixing a server. This takes time, you need to get approval from people, and its not easily reproduced or really documented anywhere. Also, there is a lot of room for error and if things break its not easy to roll back bugs.

Problem becomes how do you automate this release process, make it streamlined, less error prone, improve how all these teams integrate and operate, and at the end of the day make the process of getting the app into the hands of your users much faster.
:::

## Common DevOps Principles

-   Collaboration

-   Continuous Integration & Delivery

-   Automation

-   Reproducibility

-   Culture change

::: notes
As the field of devops developed, there are different implementations/diff technologies of what devops means - these happen differently at different companies But there have been some common philosophies and best practices that have come out that I've seen consistently across the entire ecosystem.

First - **everyone** that's involved in the creation of this application should be collaborating and working together. This is my wink wink moment for you all of why devops is so important for data scientists

Then we have this concept of **Continuous Integration & Delivery** - we'll take about this in greater length in a few minutes - but this is the process of 1. the coding of the app 2. the versioning of that code is some kind of repository 3. testing those changes 4. integrating them into the app if those tests are passed 5. And then that continuous process of releasing those changes into production

So for the CI/CD process to work and specifically to work quickly - we will need some level of **automation** as we move through that cyclical process. You don't want to have to pause things to get approval or manually change things when tests pass - you want it to get to the user as quickly as possible after everything has been tested.

The next piece is **reproducibility**. You have different teams working on different pieces of the puzzle, but at the end of the day the end result is the same. Everyone is working on that same app - in this case our stock platform. So as jobs go from one team to another team and as your app goes from development to testing to finally your users, you want to make sure that there's a common ecoystem that everyone is working in. When you're testing your app you want to make sure that your environment is as similar to what is going to be in real-life or what is called "production". You also want to make sure that your code itself is reproducible and that it works for users regardless of their location or their computer or their browser maybe.

The last piece that I find really interesting is the concept of **culture change**. So what needs to change in your organization so that you're able to function while still holding this tension or conflict between speed and stability. How do you make sure that teams that have different incentives - for example security team vs. a data team - are able to work together.

So let me pause - that's a lot - everyone got a bit of a history lesson but as far as i'm aware no one here is a software developer or an IT engineer. So that brings me to this very important question: But
:::

## Why should we as data scientists care about this?

::: notes
lets have a little thought experiment
:::

## Has this ever happened to you?

::: columns
::: {.column width="50%"}
[You come back to code from a year ago and now it doesnt run!]{.fragment fragment-index="1"}
:::

::: {.column width="50%"}
[Reproducibility]{.fragment fragment-index="2" style="color: blue;"}
:::
:::

::: columns
::: {.column width="50%"}
[You need to hand off your model to the Engineering team but they only code in Java]{.fragment fragment-index="3"}
:::

::: {.column width="50%"}
[Continuous Integration & Delivery & Collaboration]{.fragment fragment-index="4" style="color: blue;"}
:::
:::

::: columns
::: {.column width="50%"}
[Your boss asks you to share that Shiny app with a client but the ops team is too busy working on their roadmap to help you deploy it somewhere.]{.fragment fragment-index="5"}
:::

::: {.column width="50%"}
[Culture Change]{.fragment fragment-index="6" style="color: blue;"}
:::
:::

## Why should data scientists/analysts care about DevOps?

::: incremental
-   Data scientists are developers!

-   Data science careers have moved from academic sphere to tech and software but education hasnt always followed

-   Automation, collaboration, testing can dramatically improve data work and improve reproducibility

-   The many hats of a data scientist

-   Improve collaboration & communication with other teams
:::

::: notes
spent a lot of time talking about teams working together to create a shared product. Data scientists are a part of that team. DS is a relatively new field and creating data-intensive apps is a huge part of tech world today.

DS career paths started in academia - not a lot of best practices are taught
:::

## Responsibility of the analyst

::: columns
::: {.column width="50%"}
![](images/Screenshot%202023-08-22%20at%203.26.22%20PM.png)
:::

::: {.column width="50%"}
![](images/Screenshot%202023-09-10%20at%2012.18.42%20PM.png)
:::
:::

::: notes
I mentioned before that a lot of DS comes from academia and research. So the concept of reproducing your results - especially if those results play a role in how medicines or medical devices are developed - is incredibly important.

2005 essay by John Ioannidis in scientific journal on what is known as the replicability crisis in scientific publishing, arguing that majority medical research studies cannot be replicated.

So as data scientists and we are curators of the data and are responsible for its legitimacy in many ways - obv cant always control it of course.

This second paper started looking a method of reproducing results - namely Jupyter notebooks - and found a lot of ways that reproducibility was improved but also a lot of places where things could have been done better and some best practices for how to do that - in what we call literate programming.

**27,271** Notebooks:

-   **11,454** could not declare dependencies

-   **5,429** could not successfully install declared dependencies

-   **9,185** returned an error when ran

-   **324** returned a different result than originally reported

Let's get back to our principles:
:::

## The Devops Process Flow

![](images/Concept%20Map.jpg){width="690"}

## Proliferation of tools

![](images/ecosystem.png)

::: notes
proliferation of tools, source code management, repo management, build tools, data management, deployment, container services, config management, monitoring, cloud services
:::

## An opinionated take on tools

-   CI/CD
-   Environment Management
-   Version Control & Git workflows
-   Package Management
-   Automation & Build tools
-   Continuous Monitoring and Logging

::: notes
-these are the ones that we're going to be covering - lot of tools, but this is what they should help you to do -definitely not going to be a complete overview of the entire ecosystem - there's also a lot of overlap in the definitions -\
-but in my opinion the most important tool types to get you started quickly.
:::

## The CI/CD Pipeline

![](images/cicd.png)

::: notes
-   As we discussed before CI/CD is an iterative cycle of small steps to quickly build, test, and deploy your code - this is a critical component of devops.

-   So CI/CD is often said in the same breath - as it makes up a continuous pipeline - but its actually pretty discrete parts so I want to make sure we understand how they differ.

-Continuous integration (CI) - this is where you or anyone who writes code, automatically builds, tests, and commits code changes into a shared repository; This is usually triggered by an automatic process where the code is built, tested and then either passes or fails. This step is focused on improving the actual build or application as quickly as possible.

Different types of tests - from unit tests to integration tests to regression tests.

-Continuous delivery (CD) and deployment are less focused on the build but on the actual installation and distribution of your build. This includes an automated process to deploy across different environments - from development to testing and finally to production. Delivery is the process for the final release - that "push of a button step" to get to prod.

we'll talk about some examples of popular CI/CD tools in a bit - Github Actions, Jenkins, CircleCI, Gitlab CI
:::

## Environment Management {.smaller}

+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+------+
| Dev                                                                                                                                                                                                                                                                                                                                                                             | Test | Prod |
+=================================================================================================================================================================================================================================================================================================================================================================================+======+======+
| exploratory analysis and experiments \| as similar to prod as possible \| separate from dev and test \| \| often just your local desktop \| unit & integration testing \| created using code \| \| "sandbox" with data that's as close to real as possible \| data validation \| code promotion process + tests \| \| \| access to R/Python packages \| \| completely automatic |      |      |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+------+

::: notes
unit test - testing individual units of code to make sure it does what you want it to do

integration test - make sure putting pieces together doesnt introduce any errors

want to be able to reproduce the environments as closely as possible
:::

## Version Control & Workflows

![](images/Screenshot%202023-08-23%20at%2011.20.04%20AM.png)

::: notes
Version control is a main tool for Continuous Integration -

lots of variants - git, github., svn, gitlab, etc

distributed version control - everyone has their own repo

can track changes and roll them back

can fix merge conflicts

an an iterative process to build, test, collaborate on your code to above environments. Very commonly, individuals work on separate branches that are then tested and reviewed by colleagues before they are merged into a main branch.

In addition to the action of promoting your code - its also important to have processes in place for how the code integration process occurs - includes humans coming together and making some decisions -

e.g code reviews, process for your team, how to name things, pull requests, merging, feature branching, automatic tests
:::

## Lab Activity - developing locally using Quarto

üü• - I need help

üü® - I'm still working

üü© - I'm done

Login to pos.it/class with code `devops_workshop`

Lab 1 Part 1:

::: notes
Show how to login to the workshop environment and where the lab is

5 minutes
:::

## Is version control secure?

-   Our code is still saved locally
-   How do we make sure that the code we push to Github (or elsewhere) is secure?

## A short auth teaser

-   We can use a variety of data sharing "transfer protocols"
-   Protocols specify what kind of traffic is moving between 2 machines
-   Use different security mechanisms
-   Ports on the host and destination specifies where to direct the traffic

![](images/Screenshot%202023-09-07%20at%209.28.32%20AM.png)

::: notes
Add diagram - http and https two computers with ports

There are lots of diff transfer protocols; what you use depends on what kind data is being transferred and your security requirements. So for example, maybe you're sending plain text or email or a webpage.

Protocols as well as processes or application run on specific ports. A port is a virtual point where network connections start and end. Allow computers to easily differentiate between different kinds of traffic. So for example, Shiny Server runs on port 3838, Workbench runs on ...

whether its email, text, files, etc Ports are software-based and managed by a computer's operating system. Ports emails go to a different port than webpages, for instance, even though both reach a computer over the same Internet connection.
:::

## Git protocol options

| http    | https    | SSH     |
|---------|----------|---------|
| port 80 | port 443 | port 22 |

http - text sent over the internet

https - http encrypted with "SSL/TLS"

SSH - secure shell

::: notes
we'll be using https - because ... from jenny bryans happy git with R

hypertext transfer protocol When a web user wants to load or interact with a web page, their web browser sends an HTTP request to the origin server that hosts the website's files. These requests are essentially lines of text that are sent via the internet.

https : http encrypted with SSL/TLS - digital certificates that establish an encrypted connected

SSH: secure shell, public-key cryptography to authenticate the client, used for remote logins, command line execution

HTTPS is simpler. For most services besides Github, you just have to enter in your username and password, and you'll be able to push and pull code.

You don't have to juggle multiple SSH keys around to use multiple devices.

Port 443, which HTTPS uses, is open in basically any firewall that can access the internet. That isn't always the case for SSH.

The primary downside for most people is that you must enter your Git password/token every time you push. While it gets added to a cache, it's not configured to cache permanently (though this can be changed). With SSH keys, it just uses the key file on disk every time.

Where SSH takes the lead is with the authentication factor---the key. The length of it alone makes it harder to accidentally leak, and due to it being unwieldy and unique, it's generally more secure.
:::

## Reproducing your environment

What are the layers that need to be reproduced across your dev, test, and prod environments?

What's your most difficult reproducibility challenge?

## Layers of reproducibility

![](images/Screenshot%202023-09-13%20at%208.23.56%20PM.png)

::: notes
-   code - scripts, configs, applications
-   Packages
-   System - r and python depend on underlying system software - for example, spatial analysis packages, or anything that requires Java - rJava
-   OS
-   Hardware - processors Intel chip, silicon chip
:::

## Packages vs. Libraries vs. Repositories

**Package** - contains code, functions, data, and documentation.

**Library** - is a directory where packages are installed.

**Repository** - a collection of packages. CRAN is a public external repository that is a network of servers that distribute R along with R packages.

::: notes
packages - Can be be distributed as SOURCE (a directory with all package components), [BINARIES](https://solutions.posit.co/envs-pkgs/environments/repositories/index.html#binary-packages) (contains files in OS-specific format) or as a BUNDLE (compressed file containing package components, similar to source).

library - You can have user-level or project-level libraries. Run `.libPaths()` to see yours. To use a package in has to be installed in a library with `install.packages()` and then loaded into memory with `library(x)` .

repo - others include pypi, bioconducter, private repos
:::

## `renv` workflow

![](images/Screenshot%202023-09-06%20at%208.31.22%20PM.png)

::: notes
1.  Use a version control system e.g.[git](https://git-scm.com/) with [GitHub](https://github.com/)

2.  One user (should explicitly initialize `renv` in the project, This will create the initial `renv` lockfile, and also write the `renv` auto-loaders to the project's `.Rprofile` and `renv/activate.R`. These will ensure the right version of `renv` is downloaded and installed for your collaborators when they start in this project.

3.  push your code alongside the generated lockfile `renv.lock`. Be sure to also share the generated auto-loaders in `.Rprofile` and `renv/activate.R`.

4.  After this has completed, they can then use [`renv::restore()`](https://rstudio.github.io/renv/reference/restore.html) to restore the project library locally on their machine.
:::

## Example

``` {eval="FALSE"}
# install.packages("renv")
renv::init()
renv::snapshot()
lapply(.libPaths(), list.files)
```

::: footer
üîç Live code
:::

## Lab Activity - `renv` workflow & github authentication

üü• - I need help

üü® - I'm still working

üü© - I'm done

Lab 1: Part 2 & 3

::: notes
You'll be doing renv in your workbench environment both in your console for r code and in the terminal for git commands you'll also need to log in to your github account where you'll be creating an upstream repository to link with your local code.

we'll be using https auth but there's also information if you later want to test out ssh

10-15 minutes
:::

## Build tools

-   Virtualization/Containerization

-   Infrastructure as code

-   Automation with Github Actions/Jenkins/CircleCI

-   Cloud devops tools (Azure Devops, Google Cloud Build)

::: notes
-   automate common build and deployment tasks
-   for example, generating artifacts, deploying to diff environs, provisioning or deprovisioning environments -
-   some overlap here between these tools and CI/CD

Virtual/Container -prod-identical - help you build isolated environments and tested and debug code; docker, kubernetes, other container services

IaC - quickly re-provision your entire environment with code (chef, puppet, dockr, terraform, ansible) instead of fixing it, just tear it down and restart it - configuration management

tools that automate the process of building and deploying your code once it goes from your dev env to test and prod

cloud devops - run your entire devops stack in a cloud managed cloud managed platform

You also have support tools - that are used across a lot of these tools - I want to discuss one of them here - YAML
:::

::: footer
Illustration credit:
:::

## Power of YAML

-   YAML Ain't Markup Language

-   communication of data between people and computers

-   human friendly

-   configures files across many execution environments

## YAML

```         
EmpRecord:  
  emp01:
    name: Michael
    job: Manager
    skills: 
      - Improv
      - Public speaking
      - People management
  emp02:
    name: Dwight
    job: Assistant to the Manager
    skills: 
      - Martial Arts
      - Beets
      - Sales
```

-   whitespace indentation denotes structure & hierarchy

-   Colons separate keys and their values

-   Dashes are used to denote a list

## Example - YAML in action

-   Docker compose [yaml file](https://github.com/rstudio/rstudio-docker-products/blob/dev/docker-compose.yml) to spin up all 3 Posit Pro products

::: footer
üîç Live code
:::

## Exercise - Inspect your YAML

üü• - I need help

üü® - I'm still working

üü© - I'm done

Inspect your \_quarto.yml file and identify what each part of it does using the quarto site.

::: notes
2-5 minutes - render your site to help
:::

## Continuous Integration Example

![](images/Untitled%20(2).jpg)

::: notes
today - we'll be discussing GHA Actions - which is a common CI tool that is handy because it uses the same platform as your versioned repositories - inthis case github

uses yaml as a configuration tool
:::

## Other GHA Categories

-   Deployment

-   Security

-   Continuous Integration

-   Automation

-   Pages

-   Make your own!

[Examples](https://github.com/Rikagx/ssh_testing/actions/new)

## Quarto Publish Flows

### Manually

![](images/Untitled.jpg){width="400"}

### Continuous Integration

![](images/Untitled%20(1).jpg)

::: notes
can publish to quarto pub, GHP, connect, netlify, confluence, other destinations, more work to set up
:::

## GHA Structure

![](images/Screenshot%202023-09-10%20at%201.32.42%20PM.png)

**Open source ecosystem of available actions**

-   [Github Official Actions](https://www.github.com/actions)

-   [RLib Actions](https://www.github.com/r-lib/actions)

::: notes
Workflows can include tests, markdown renders, shell scripts, cron jobs, or deployments. They can be as simple or as complicated as you need. Open-source community provides a ton of examples of actions.
:::

## Actions Syntax

[Code](https://posit-conf-2023.github.io/devops/coursework_labs/01_lab_devops_CICD/Deploy_Quarto_GHA.html#part-4-publish-using-gha)

## Lab Activity

üü• - I need help

üü® - I'm still working

üü© - I'm done

Part 4 of Lab: Deploy Quarto with GHA including the exercises

::: notes
we'll be doing a few things - create a gh branch - publish to github - create a gha with a yaml file - create an api key for connect - update yaml file - push everything
:::

## Logging

log session ‚û°Ô∏è log statement ‚û°Ô∏è log entry

::: columns
::: {.column width="50%"}
```{python filename="app.py"}
import logging

# Configure the log object
logging.basicConfig(
    format='%(asctime)s - %(message)s',
    level=logging.INFO
)

# Log app start
logging.info("App Started")
```
:::

::: {.column width="50%"}
```{r filename="app.R"}
# Configure the log object
log <- log4r::logger()

# Log app start
log4r::info(log, "App Started")
```
:::
:::

::: notes
create a log session for your r or python code, write a log statement, gets added into an entry

what to log

types of logs
:::

## Monitoring

![](images/icons8-prometheus-48.png)

If you want to register metrics from your API or app with Prometheus, there is an official [Prometheus client](https://github.com/prometheus/client_python) in Python and the `{openmetrics}` package in R makes it easy to register metrics from a Plumber API or Shiny app.

![](images/icons8-grafana-48.png)

There's a great [Get Started with Grafana and Prometheus](https://grafana.com/docs/grafana/latest/getting-started/get-started-grafana-prometheus/) doc on the Grafana Labs website if you want to actually try it out.

## Part 3 Goals: Docker for Data Scientists

-   to understand different docker workflows
-   to learn common docker syntax for building and running containers
-   to get hands on experience building and running containers
-   to explore the linux file system

## Why use a container at all?

-   allows you to package up everything you need to reproduce an environment/application
-   lightweight system without much overhead
-   share containers with colleagues without requiring them to have to set up their own local machines
-   quick testing and debugging
-   allows you to easily version snapshots of your work
-   scaling up

## Our Docker Environment

![](images/Screenshot%202023-09-15%20at%2011.56.18%20AM.png)

## Workflow

![](images/Screenshot%202023-09-15%20at%2012.58.53%20PM.png){width="800"}

::: notes
dockerfile - is a script of instructions for how to build an image

image - everything you need to run an application - all the layers that build the environment, dependencies, libraries, files

container - isolated instance of a running image. you can create, stop, start, restart, containers. When a container is removed/deleted any changes to its state that arent stored in some kind of persistent storage disappear. Called ephemeral container - Think of a container as a snapshot in time of a particular application.

Missing piece - repository - for images, like dockerhub, container registry cloud services, private registries

Build - Run - Push
:::

## Architecture

![](images/Screenshot%202023-08-30%20at%2010.12.11%20AM-01.png)

::: notes
On the left we have the client - think of this as your computer or perhaps a computer somewhere in the cloud

on the right you have the server - this the docker host which runs something called the Docker daemon - you'll be communicating with the Docker daemon via a command line interface.

The host can be remote or it can be on your computer with the client - so for example, you can download something called Docker Engine. In most cases the host is running on a Linux OS. (in different laptop OS, Docker Desktop uses a lightweight VM under the hood)

Docker engine is a container runtime that runs on different OS's. Sets up the isolated environment for your container.

what the heck is the Docker daemon - its a service that does all the heavy lifting of building and running your containers

registry - upload and download images

Docker Desktop includes the Docker daemon (dockerd), the Docker client (docker), Docker Compose - another client, Docker Content Trust, Kubernetes, and Credential Helper.
:::

## Images

![](images/Screenshot%202023-09-15%20at%2012.25.29%20PM.png){width="800"}

::: notes
made up of individual layers so its really quick to build isolating applications into their own image
:::

## Dockerhub Registry

https://hub.docker.com/search?q=

## Containers

![](images/Screenshot%202023-09-15%20at%2012.14.04%20PM.png)

::: notes
runnable instance of an image.

From the bottom up Containers run on some sort of infrastructure - this could be your laptop or a server somewhere in the cloud

host OS - shared OS between container instances, dont need a guest os for each one, makes them really light and able to spinup in milliseconds

containers are very lightweight which makes it really easy and quick to spin them up

Instead, the Docker daemon communicates directly with the host operating system and knows how to ration out resources for the running Docker containers.
:::

## How can data scientists use docker?

## Example - testing & versioning

``` bash
docker pull postgres:12
docker pull postgres:latest
docker container ls -a
docker run -d -e POSTGRES_PASSWORD=mysecretpassword --name postgres_early imageID
docker run -d -e POSTGRES_PASSWORD=mysecretpassword --name postgres_new imageID
docker container ls -a
docker stop
docker restart
```

::: footer
üîç Live code
:::

::: notes
can pull but also if you just run - will put it from hub if doenst find locally Let's see an example of what this looks like in practice. Lets say we need to use a postgres sql database for some testing - but we want to test using an older and a newer version of postgres.

docker image ls - lets list all the images that we have

docker pull postgres:12 - see how its pulling and extracting all these layers - but what if we want a newer version or what if we need to run both versions on our machine

docker pull postgres:latest - notice how some of these layers already exist so it takes a lot less time
:::

## Example - reproduce environments

https://hub.docker.com/u/rocker

```         
# pull the image
docker pull rocker/r-base

# run container
docker run --rm -it rocker/r-base
```

## Example - isolate applications

https://hub.docker.com/u/rstudio

**DO NOT RUN!**

```         
docker run -it --privileged \
    -p 3939:3939 \
    -e RSC_LICENSE=$RSC_LICENSE \
    rstudio/rstudio-connect:ubuntu2204
```

## Docker as deployment strategy

![](images/dep_strategy.png)

## Example - Docker in CI pipeline

```         
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      -
        name: Checkout
        uses: actions/checkout@v3
      -
        name: Login to Docker Hub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}
      -
        name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
      -
        name: Build and push
        uses: docker/build-push-action@v4
        with:
          context: .
          file: ./Dockerfile
          push: true
          tags: ${{ secrets.DOCKERHUB_USERNAME }}/latest
```

::: notes
-   Data scientists benefit from Docker's consistency and reproducibility.

-   Create isolated environments for different experiments.

-   Share work with colleagues without environment setup issues.

-   **Consistency:** Containers ensure that applications run the same way across different environments.

-   **Isolation:** Containers isolate applications and their dependencies, preventing conflicts.

-   **Portability:** Containers can run on any system that supports Docker, reducing "it works on my machine" issues.

## 
:::

## Modes for running containers

+------------------------------------------------------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Mode                                                       | Run command       | Use case                                                                                                                                                                                                           |
+============================================================+===================+====================================================================================================================================================================================================================+
| Detached                                                   | `docker run -d`   | This runs the container in the **background** so the container keeps running until the application process exits, or you stop the container. Detached mode is often used for production purposes.                  |
+------------------------------------------------------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Interactive + terminal                                     | `docker run -it`  | This runs the container in the **foreground** so you are unable to access the command prompt. Interactive mode is often used for development and testing.                                                          |
+------------------------------------------------------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Remove everything once the container is done with its task | `docker run --rm` | This mode is used on foreground containers that perform **short-term tasks** such as tests or database backups. Once it is removed anything you may have downloaded or created in the container is also destroyed. |
+------------------------------------------------------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

## Lab Activity - Running containers

üü• - I need help

üü® - I'm still working

üü© - I'm done

Lab 2: Part 1

## Container Debugging

```         
docker run -it -d ubuntu
docker container ls -a 
docker exec -it CONTAINER_ID bash

docker container run -d --name mydb \
 --name mydb \
 -e MYSQL_ROOT_PASSWORD=my-secret-pw \ 
 mysql
 
 docker container logs mydb
```

::: footer
üîç Live code
:::

## Lab Activity - Debugging Containers

üü• - I need help

üü® - I'm still working

üü© - I'm done

Complete Lab 2: Part 2

## Port Mapping with `docker run -p`

`docker run -p host_port:container_port`

![](images/port%20mapping.png){width="600"}

```         
docker pull httpd:alpine
docker pull httpd:latest

docker inspect --format='{{.Config.ExposedPorts}}' httpd:latest
docker inspect --format='{{.Config.ExposedPorts}}' httpd:alpine

docker run -p DockerHostPort:ApplicationPort

docker run -d -p 6574:80 --name httpd-latest httpd:latest
curl http://localhost:81

docker run -d -p 80:80 --name httpd-alpine httpd:alpine
curl http://localhost:80
```

::: footer
üîç Live code
:::

## Persisting data with Docker

-   State is persistent information that is recorded and recalled later

-   Containers are designed to be ephemeral e.g. stateless by default

-   Data applications are usually stateful and more complex to deploy

## Docker examples

-   volume mount

-   bind mount

-   external storage

-   shared file system

## Putting it all together

https://github.com/rstudio/rstudio-docker-products/blob/dev/docker-compose.yml

::: notes
-   **docker-compose:** A tool for defining and running multi-container Docker applications.
-   Uses a YAML file to define services, networks, and volumes.
-   Simplifies the orchestration of complex applications.
:::

## Lab Activity

üü• - I need help

üü® - I'm still working

üü© - I'm done

Complete Lab 2: Part 3 Complete Lab 2: Part 4

## Building Docker Images

-   Images are build using a Dockerfile or interactively "on-the-fly"

-   Steps to version and share your images on Dockerhub (or a different repository)

make this a diagram Step 1: Commit Step 2: Tag Step 3: Push

## Lab Activity

üü• - I need help

üü® - I'm still working

üü© - I'm done

Complete Lab 2: Part 5

## Dockerfile Build Commands

| Command | Description |
|---------|-------------|
| FROM    |             |
| ENV     |             |
| COPY    |             |
| RUN     |             |
|         |             |
|         |             |
|         |             |

## Dockerfile Example

Walk through Posit Connect [Dockerfile](https://github.com/rstudio/rstudio-docker-products/blob/dev/connect/Dockerfile.ubuntu2204)

## Activity

Complete Lab 2: Part 6

## Part 4: Data Science in Production

## Data Science in Production {.content-dark}

-   Presentation Layer

-   Processing Layer

-   Data store Layer

## Choosing the right presentation layer

-   [Alex's flow chart](https://do4ds.com/chapters/sec1/1-2-proj-arch.html)

-   credit text

## Choosing an API

![](images/apis.png)

## Production "State"

Questions to ask once your content is able to be consumed by your intended audience

-   Where is it deployed?

-   Is it secure and accessible?

-   Is it maintainable?

-   Does it scale?

-   Is your code efficiently written?

-   Is it tested?

## Where is it deployed?

list of PaaS / Caas and highlight Connect

## Lab Activity:

üü• - I need help

üü® - I'm still working

üü© - I'm done

Part 1: Host API on Posit Connect

## Is it secure?

-   Basic Auth

-   API keys

-   Token-based

## Securing credentials

-   username and password

-   centralized credential server

-   SSO

## Is it accessible?

RBAC

## Lab Activity:

üü• - I need help

üü® - I'm still working

üü© - I'm done

Part 2:

## Is it maintainable

git-backed deploymnet

## Is it scalable?

scaling up vs. scaling out

connect shiny resource options

## Is your code efficient?

-   data storage

-   computations

-   caches

## Is it tested

testing as part of CI/CD

## 
